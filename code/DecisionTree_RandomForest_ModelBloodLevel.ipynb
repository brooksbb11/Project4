{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RndAUQ-kI6r7",
        "outputId": "ccb8273f-1084-4856-91a0-4e92bcbc5d7a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGszrQH4ZL9N",
        "outputId": "7f35ec19-d381-48c8-94b1-964ac361f228"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: findspark in /usr/local/lib/python3.10/dist-packages (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQU1b7RfhKN2",
        "outputId": "da2fa568-f132-442a-adb3-06e866eecc07"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spark in /usr/local/lib/python3.10/dist-packages (0.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.x  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.4.0'\n",
        "spark_version = 'spark-3.4.0'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop3.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop3\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "5sb_4Jz3Y8gG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aae751f-697a-41cc-8f7a-3e3a7e3350a6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.81)] [Connecting to security.ub\r                                                                               \rHit:2 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadconte\r                                                                               \rHit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\r0% [Waiting for headers] [Connected to ppa.launchpadcontent.net (185.125.190.52\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 109 kB in 2s (65.2 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0J9b0vFtI0Cb"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.types import StructType,StructField,StringType, DateType,IntegerType\n",
        "from pyspark import SparkFiles\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"LeadBloodLevels\").getOrCreate()"
      ],
      "metadata": {
        "id": "iZ6-ajD5h2EC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkFiles\n",
        "\n",
        "lead_df = spark.read.csv(\"cleaned_blood_data.csv\", sep=\",\", header=True,inferSchema=True)"
      ],
      "metadata": {
        "id": "EHBXCwsKh_ir"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Second DataFrame Lead levels in blood\n",
        "lead_df.show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJ4o_wF2P7Dr",
        "outputId": "65ad3df6-4102-4117-daf4-c368f87188e4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+-----+----+-------------+-----+------------------+-----------+------------+----------+---------------------------+--------------+-------+--------------------+--------------------+\n",
            "|County|County Code|  Zip|Year|Year of Birth|Tests|Less than 5 mcg/dL|5-10 mcg/dL|10-15 mcg/dL|15+ mcg/dL|Total Elevated Blood Levels|Rate per 1,000|Percent|   Zip Code Location|     County Location|\n",
            "+------+-----------+-----+----+-------------+-----+------------------+-----------+------------+----------+---------------------------+--------------+-------+--------------------+--------------------+\n",
            "|Albany|          1|12009|2020|         2019|   30|              30.0|        0.0|         0.0|       0.0|                        0.0|           0.0|    0.0|(42.697778, -74.0...|(42.588271, -73.9...|\n",
            "|Albany|          1|12023|2020|         2019|    7|               7.0|        0.0|         0.0|       0.0|                        0.0|           0.0|    0.0|(42.60636, -74.1438)|(42.588271, -73.9...|\n",
            "|Albany|          1|12054|2020|         2017|    6|               6.0|        0.0|         0.0|       0.0|                        0.0|           0.0|    0.0|(42.60522, -73.87...|(42.588271, -73.9...|\n",
            "|Albany|          1|12083|2020|         2018|    6|               6.0|        0.0|         0.0|       0.0|                        0.0|           0.0|    0.0|(42.416705, -74.0...|(42.588271, -73.9...|\n",
            "|Albany|          1|12083|2020|         2019|    7|               7.0|        0.0|         0.0|       0.0|                        0.0|           0.0|    0.0|(42.416705, -74.0...|(42.588271, -73.9...|\n",
            "|Albany|          1|12084|2020|         2018|   30|              30.0|        0.0|         0.0|       0.0|                        0.0|           0.0|    0.0|(42.699325, -73.8...|(42.588271, -73.9...|\n",
            "|Albany|          1|12110|2020|         2017|   10|              10.0|        0.0|         0.0|       0.0|                        0.0|           0.0|    0.0|(42.747077, -73.7...|(42.588271, -73.9...|\n",
            "|Albany|          1|12143|2020|         2018|   14|              14.0|        0.0|         0.0|       0.0|                        0.0|           0.0|    0.0|(42.47172, -73.82...|(42.588271, -73.9...|\n",
            "|Albany|          1|12158|2020|         2017|    6|               6.0|        0.0|         0.0|       0.0|                        0.0|           0.0|    0.0|(42.551716, -73.8...|(42.588271, -73.9...|\n",
            "|Albany|          1|12158|2020|         2018|   28|              28.0|        0.0|         0.0|       0.0|                        0.0|           0.0|    0.0|(42.551716, -73.8...|(42.588271, -73.9...|\n",
            "+------+-----------+-----+----+-------------+-----+------------------+-----------+------------+----------+---------------------------+--------------+-------+--------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#look at the statistics of lead in blood levels of children\n",
        "lead_df.select(['Less than 5 mcg/dL','5-10 mcg/dL','10-15 mcg/dL','15+ mcg/dL']).describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn_TPgdwRECq",
        "outputId": "658cf9c9-858d-4857-ddcf-37ee9f71f722"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+--------------------+------------+----------+\n",
            "|summary|Less than 5 mcg/dL|         5-10 mcg/dL|10-15 mcg/dL|15+ mcg/dL|\n",
            "+-------+------------------+--------------------+------------+----------+\n",
            "|  count|              1817|                1817|        1817|      1817|\n",
            "|   mean| 25.73913043478261|0.022564667033571822|         0.0|       0.0|\n",
            "| stddev| 33.12551510551277|  0.3969007470413673|         0.0|       0.0|\n",
            "|    min|               6.0|                 0.0|         0.0|       0.0|\n",
            "|    max|             376.0|                 9.0|         0.0|       0.0|\n",
            "+-------+------------------+--------------------+------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lead in Blood Data\n",
        "First read in the data using pyspark, dropped columns that did not have testable data in them, then split the data into Training and testing sets to check the accuracy of the following question:\n"
      ],
      "metadata": {
        "id": "VfTm9AZATtHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop specific columns that are not needed I created a variable, so it would copy and not edit the original dataframe\n",
        "df=lead_df.drop('Zip Code Location','County Location','Total Elevated Blood Levels','County Code','Zip','Year','Rate per 1,000','Percent','5-10 mcg/dL','10-15 mcg/dL','15+ mcg/dL')\n",
        "\n",
        "df.show(2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tr5hqrsT1KL",
        "outputId": "0b9cfb81-3368-46b5-a619-b78e05067117"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+-----+------------------+\n",
            "|County|Year of Birth|Tests|Less than 5 mcg/dL|\n",
            "+------+-------------+-----+------------------+\n",
            "|Albany|         2019|   30|              30.0|\n",
            "|Albany|         2019|    7|               7.0|\n",
            "+------+-------------+-----+------------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#rename columns to eliminate spaces\n",
        "df=df.withColumnRenamed(\"Year of Birth\",\"BirthYear\")\\\n",
        "                    .withColumnRenamed(\"Less than 5 mcg/dL\",\"Level\")\n",
        "df.show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UAuwz_bbLl-",
        "outputId": "e7491972-ba0b-4f9e-aa3c-cb8a919778f2"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+-----+-----+\n",
            "|County|BirthYear|Tests|Level|\n",
            "+------+---------+-----+-----+\n",
            "|Albany|     2019|   30| 30.0|\n",
            "|Albany|     2019|    7|  7.0|\n",
            "+------+---------+-----+-----+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split Train/Test lead Data"
      ],
      "metadata": {
        "id": "Deud8UMWVxXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "#create an indexer\n",
        "county_indexer=StringIndexer(inputCol='County',outputCol='CountyIndex')\n"
      ],
      "metadata": {
        "id": "Jr6Tf27hgimF"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import OneHotEncoder\n",
        "onehot_encoder=OneHotEncoder(inputCol=\"CountyIndex\",outputCol=\"County_vec\")\n"
      ],
      "metadata": {
        "id": "klSnDXAwqamw"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Merge columns into a vector column\n",
        "vector_assembler=VectorAssembler(inputCols=['BirthYear','Tests','Level','County_vec'],outputCol=\"features\")"
      ],
      "metadata": {
        "id": "b-gl8yyiwLYy"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a Pipeline\n",
        "pipeline=Pipeline(stages=[county_indexer,onehot_encoder,vector_assembler])"
      ],
      "metadata": {
        "id": "F_8JXYC8co9o"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fit and transform\n",
        "df_transformed=pipeline.fit(df).transform(df)\n",
        "df_transformed.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "do3pg9Crw4LS",
        "outputId": "c5f5c99e-2247-4fa7-98c7-c3dbb8028814"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+-----+-----+-----------+---------------+--------------------+\n",
            "|County|BirthYear|Tests|Level|CountyIndex|     County_vec|            features|\n",
            "+------+---------+-----+-----+-----------+---------------+--------------------+\n",
            "|Albany|     2019|   30| 30.0|       13.0|(55,[13],[1.0])|(58,[0,1,2,16],[2...|\n",
            "|Albany|     2019|    7|  7.0|       13.0|(55,[13],[1.0])|(58,[0,1,2,16],[2...|\n",
            "|Albany|     2017|    6|  6.0|       13.0|(55,[13],[1.0])|(58,[0,1,2,16],[2...|\n",
            "+------+---------+-----+-----+-----------+---------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_transformed=df_transformed.select('CountyIndex','features')"
      ],
      "metadata": {
        "id": "g0fJFnBpxMr6"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the data into training and testing sets\n",
        "train,test=df_transformed.randomSplit([0.8,0.2],seed=42)\n"
      ],
      "metadata": {
        "id": "3my5Ek4rdPGP"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Decsion Tree Classifier\n",
        "tree=DecisionTreeClassifier(labelCol=\"CountyIndex\",featuresCol=\"features\")"
      ],
      "metadata": {
        "id": "6EaDcfrIdthT"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train our model using training data\n",
        "model=tree.fit(train)"
      ],
      "metadata": {
        "id": "sTPKu0DD0ZHR"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test our model and make predictions using testing data\n",
        "prediction=model.transform(test)"
      ],
      "metadata": {
        "id": "pwLxAkW9fL50"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"CountyIndex\", predictionCol=\"prediction\",metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(prediction)\n",
        "print(\"Test Error = %g \" % (1.0 - accuracy))\n",
        "print(\"Accuracy = %g \" % accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8gkyaDz2NIP",
        "outputId": "d7707aa9-ccc6-40fe-bc13-b0491c41c34f"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error = 0.51746 \n",
            "Accuracy = 0.48254 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "# train our model using training data\n",
        "\n",
        "rf = RandomForestClassifier(labelCol=\"CountyIndex\",featuresCol=\"features\", numTrees=12)\n",
        "model = rf.fit(train)\n",
        "# test our model and make predictions using testing data\n",
        "predictions = model.transform(test)\n",
        "predictions.select(\"prediction\", \"CountyIndex\")\n",
        "# evaluate the performance of the classifier\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"CountyIndex\",predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
        "print(\"Accuracy = %g \" % accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUG0Z7-X3Jwq",
        "outputId": "f28809cd-e7fb-4f3e-94e9-cf352015cadf"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error = 0.27619\n",
            "Accuracy = 0.72381 \n"
          ]
        }
      ]
    }
  ]
}